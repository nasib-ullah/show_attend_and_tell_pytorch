{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device in Use:  cuda\n",
      "Device Properties:  _CudaDeviceProperties(name='GeForce RTX 2080 Ti', major=7, minor=5, total_memory=11018MB, multi_processor_count=68)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from dictionary import Vocabulary,EOS_token,PAD_token,SOS_token,UNK_token\n",
    "from utils import maskNLLLoss,normalizeString\n",
    "from config import Config,Path\n",
    "from model import ShowAttendTell\n",
    "from data import DataHandler\n",
    "from evaluate import Evaluator\n",
    "\n",
    "from torchvision.models import resnet101\n",
    "\n",
    "dataset_path = '/media/nasibullah/Ubuntu/DataSets/Vision_Language_Tasks/COCO2014/'\n",
    "path = Path(dataset_path)\n",
    "\n",
    "print('Device in Use: ',Config.device)\n",
    "print('Device Properties: ',torch.cuda.get_device_properties(Config.device))\n",
    "\n",
    "# changes for resnet\n",
    "Config.model_name = 'RESNET101_LSTM_'\n",
    "Config.encoder_arch = 'resnet'\n",
    "Config.feat_size = 1024\n",
    "Config.batch_size = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json.load(open('results/VGG_LSTM_39.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original Model Implementation Details\n",
    "  # Encoder - VGG19 14×14×512 feature map of the fourth convolutional layer before max pooling. 196 × 512 \n",
    "  # mini-batch - 64\n",
    "  # stopping criterion - early stopping on BLEU score\n",
    "  # model selection - BLEU on our validation set\n",
    "  # vocabulary size - 10,000\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#We observed a breakdown in correlation between the validation set log-likelihood and BLEU in the later stages of \n",
    "#training during our experiments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size : 22905\n"
     ]
    }
   ],
   "source": [
    "voc = Vocabulary('COCO_TRAIN')\n",
    "voc.load()\n",
    "#voc.trim(min_count=3) # remove words having freq0.000001,0.0001,1.0uency less than min_count\n",
    "print('Vocabulary size :',voc.num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datahandler = DataHandler(dataset_path,voc)\n",
    "train_dset,val_dset,test_dset = datahandler.getDataSets()\n",
    "train_loader,val_loader,test_loader = datahandler.getDataLoaders(train_dset,val_dset,test_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([42, 3, 224, 224]),\n",
       " torch.Size([18, 42]),\n",
       " torch.Size([18, 42]),\n",
       " torch.Size([42]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "features, targets, mask, max_length,ides= dataiter.next()\n",
    "\n",
    "features.size(),targets.size(),mask.size(),ides.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nasibullah/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "model = ShowAttendTell(voc,Config)\n",
    "#model.load('Save/VGG_LSTM_encoder_39.pt','Save/VGG_LSTM_decoder_39.pt')\n",
    "\n",
    "val_evaluator = Evaluator(Config.model_name,path.prediction_file_path,path.val_annotation_file,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch : lr, tf ratio  Bleu4(epoch no)\n",
    "# 1-10 : 1e-3, 0.5       14\n",
    "# 10-15 : 1e-3, 0.5      15\n",
    "# 15-25 : 1e-4, 0.4      15.5\n",
    "# 25-30 : 1e-3, 0.7      18\n",
    "# 30-33 : 1e-4, 0.8      20.6 (32)\n",
    "# 33 - 35 : 1e-4, 0.9    22.9 (35)  \n",
    "# 36 - 38 : 1e-4, 1.0    24.1 (38)\n",
    "# 39 - 41 : 1e-4, 1.0    24.16 (39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1,6    1e-3     0.7     19\n",
    "6,16   1e-4     1.0     25.5\n",
    "16,21  1e-4     1.0     25.6\n",
    "21,26  1e-4     1.0     25.8\n",
    "26,31  1e-4     1.0     25.79\n",
    "31,34  1e-3     1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nasibullah/Anaconda_Workspace/Vision and Language/Image Captioning/Show Attend and Tell/COCO2014/utils.py:33: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729096996/work/aten/src/ATen/native/IndexingUtils.h:25.)\n",
      "  loss = crossEntropy.masked_select(mask).mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 400; Percent complete: 20.3%; Average loss: 2.2635\n",
      "Iteration: 800; Percent complete: 40.6%; Average loss: 2.3259\n",
      "Iteration: 1200; Percent complete: 60.9%; Average loss: 2.3279\n",
      "Iteration: 1600; Percent complete: 81.2%; Average loss: 2.3349\n",
      " Epoch : 31  Loss : 2.3165232126150834\n",
      "{'testlen': 396327, 'reflen': 391713, 'guess': [396327, 355823, 315319, 274815], 'correct': [264825, 127529, 53770, 22566]}\n",
      "ratio: 1.0117790320974769\n",
      "[(['Bleu_1', 'Bleu_2', 'Bleu_3', 'Bleu_4'], [0.6681982302492622, 0.48937314047448244, 0.34436847291117556, 0.24064180477800723]), ('METEOR', 0.22158995574757132), ('ROUGE_L', 0.4921808333150701), ('CIDEr', 0.7383353658108943)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nasibullah/Anaconda_Workspace/Vision and Language/Image Captioning/Show Attend and Tell/COCO2014/utils.py:33: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729096996/work/aten/src/ATen/native/IndexingUtils.h:25.)\n",
      "  loss = crossEntropy.masked_select(mask).mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 400; Percent complete: 20.3%; Average loss: 2.2941\n",
      "Iteration: 800; Percent complete: 40.6%; Average loss: 2.3023\n",
      "Iteration: 1200; Percent complete: 60.9%; Average loss: 2.3040\n",
      "Iteration: 1600; Percent complete: 81.2%; Average loss: 2.3096\n",
      " Epoch : 32  Loss : 2.3055361043976084\n",
      "{'testlen': 389391, 'reflen': 387313, 'guess': [389391, 348887, 308383, 267879], 'correct': [261924, 126138, 53577, 22226]}\n",
      "ratio: 1.0053651697722488\n",
      "[(['Bleu_1', 'Bleu_2', 'Bleu_3', 'Bleu_4'], [0.6726503694230204, 0.49314572107715615, 0.34829413963614425, 0.24332699097255486]), ('METEOR', 0.22277604975396034), ('ROUGE_L', 0.49419720301865916), ('CIDEr', 0.7502807899326497)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nasibullah/Anaconda_Workspace/Vision and Language/Image Captioning/Show Attend and Tell/COCO2014/utils.py:33: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729096996/work/aten/src/ATen/native/IndexingUtils.h:25.)\n",
      "  loss = crossEntropy.masked_select(mask).mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 400; Percent complete: 20.3%; Average loss: 2.2501\n",
      "Iteration: 800; Percent complete: 40.6%; Average loss: 2.2641\n",
      "Iteration: 1200; Percent complete: 60.9%; Average loss: 2.2688\n",
      "Iteration: 1600; Percent complete: 81.2%; Average loss: 2.2729\n",
      " Epoch : 33  Loss : 2.265338014922364\n",
      "{'testlen': 394132, 'reflen': 390497, 'guess': [394132, 353628, 313124, 272620], 'correct': [264064, 128072, 54300, 23089]}\n",
      "ratio: 1.0093086502585142\n"
     ]
    }
   ],
   "source": [
    "Config.encoder_lr = 1e-5\n",
    "Config.decoder_lr = 1e-3\n",
    "Config.teacher_forcing_ratio = 1.0\n",
    "model.update_hyperparam(Config)\n",
    "\n",
    "for epoch in range(31,34):\n",
    "    model.train()\n",
    "    loss = model.train_epoch(train_loader)\n",
    "    print(' Epoch :',epoch,' Loss :',loss)\n",
    "    scores = val_evaluator.evaluate(model,epoch)\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #val_evaluator = Evaluator(Config.model_name,path.prediction_file_path,path.val_annotation_file,val_loader)\n",
    "# scores = val_evaluator.evaluate(model,5)\n",
    "# print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder(features.to(Config.device)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization\n",
    "dataiter = iter(val_loader)\n",
    "features,_,_,_,_ = dataiter.next()\n",
    "\n",
    "print(features.size())\n",
    "ct,ctx,aw = model.Greedy_Decoding(features.to(Config.device))\n",
    "ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [14, 14]\n",
    "import skimage.transform\n",
    "\n",
    "num = 10\n",
    "words = ctx[num].split(' ')\n",
    "img = features[num].permute(1,2,0).numpy()\n",
    "print(ctx[num])\n",
    "plt.subplot(4, 5, 1)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "\n",
    "for t in range(len(words)):\n",
    "        if t > 15:\n",
    "            break\n",
    "        plt.subplot(4, 4, t+2)\n",
    "        plt.text(0, 1, '%s'%(words[t]) , color='black', backgroundcolor='white', fontsize=10)\n",
    "        plt.imshow(img)\n",
    "        alp_curr = aw[t,num,:].reshape(14,14)\n",
    "        alp_img = skimage.transform.pyramid_expand(alp_curr, upscale=16, sigma=20)\n",
    "        plt.imshow(alp_img, alpha=0.70)\n",
    "        plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Result generation for test files\n",
    "result = []\n",
    "ide_list = []\n",
    "caption_list =[]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(test_loader):\n",
    "        ides, features = data\n",
    "        cap,cap_txt = model.Greedy_Decoding(features.to(device))\n",
    "        ide_list += list(ides.cpu().numpy())\n",
    "        caption_list += cap_txt\n",
    "for a in zip(ide_list,caption_list):\n",
    "    result.append({'image_id':a[0].item(),'caption':a[1].strip()}) \n",
    "    \n",
    "predicted_test_file = os.path.join(prediction_file_path,'captions_test2014_SAT_results.json') \n",
    "with open(predicted_test_file, 'w') as fp:\n",
    "    json.dump(result,fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
